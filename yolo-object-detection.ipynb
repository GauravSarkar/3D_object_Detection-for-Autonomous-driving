{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"data = \"../input/3d-object-detection-for-autonomous-vehicles\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-11T15:27:01.089445Z","iopub.execute_input":"2021-07-11T15:27:01.08998Z","iopub.status.idle":"2021-07-11T15:27:01.094155Z","shell.execute_reply.started":"2021-07-11T15:27:01.089947Z","shell.execute_reply":"2021-07-11T15:27:01.093429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import struct\nimport numpy as np\nfrom keras.layers import Conv2D\nfrom keras.layers import Input\nfrom keras.layers import BatchNormalization\nfrom keras.layers import LeakyReLU\nfrom keras.layers import ZeroPadding2D\nfrom keras.layers import UpSampling2D\nfrom keras.layers.merge import add, concatenate\nfrom keras.models import Model","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-07-11T15:27:01.102166Z","iopub.execute_input":"2021-07-11T15:27:01.102625Z","iopub.status.idle":"2021-07-11T15:27:06.77973Z","shell.execute_reply.started":"2021-07-11T15:27:01.102593Z","shell.execute_reply":"2021-07-11T15:27:06.778713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _conv_block(inp, convs, skip=True):\n    x = inp\n    count = 0\n    for conv in convs:\n        if count == (len(convs) - 2) and skip:\n            skip_connection = x\n        count += 1\n        if conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x) \n        x = Conv2D(conv['filter'],\n                   conv['kernel'],\n                   strides=conv['stride'],\n                   padding='valid' if conv['stride'] > 1 else 'same', \n                   name='conv_' + str(conv['layer_idx']),\n                   use_bias=False if conv['bnorm'] else True)(x)\n        if conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n        if conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n    return add([skip_connection, x]) if skip else x","metadata":{"execution":{"iopub.status.busy":"2021-07-11T15:27:06.781416Z","iopub.execute_input":"2021-07-11T15:27:06.781698Z","iopub.status.idle":"2021-07-11T15:27:06.796608Z","shell.execute_reply.started":"2021-07-11T15:27:06.781654Z","shell.execute_reply":"2021-07-11T15:27:06.794273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_yolov3_model():\n    input_image = Input(shape=(None, None, 3))\n    # Layer  0 => 4\n    x = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n                                  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n                                  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n                                  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n    # Layer  5 => 8\n    x = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n                        {'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n    # Layer  9 => 11\n    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n    # Layer 12 => 15\n    x = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n                        {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n                        {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n    # Layer 16 => 36\n    for i in range(7):\n        x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n                            {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n    skip_36 = x\n    # Layer 37 => 40\n    x = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n    # Layer 41 => 61\n    for i in range(7):\n        x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n                            {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n    skip_61 = x\n    # Layer 62 => 65\n    x = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n    # Layer 66 => 74\n    for i in range(3):\n        x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n                            {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n    # Layer 75 => 79\n    x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\n    # Layer 80 => 82\n    yolo_82 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n                              {'filter':  255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)\n    # Layer 83 => 86\n    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\n    x = UpSampling2D(2)(x)\n    x = concatenate([x, skip_61])\n    # Layer 87 => 91\n    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\n    # Layer 92 => 94\n    yolo_94 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n                              {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)\n    # Layer 95 => 98\n    x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\n    x = UpSampling2D(2)(x)\n    x = concatenate([x, skip_36])\n    # Layer 99 => 106\n    yolo_106 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n                               {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)\n    model = Model(input_image, [yolo_82, yolo_94, yolo_106])\n    return model\n\nclass WeightReader:\n    def __init__(self, weight_file):\n        with open(weight_file, 'rb') as w_f:\n            major,\t= struct.unpack('i', w_f.read(4))\n            minor,\t= struct.unpack('i', w_f.read(4))\n            revision, = struct.unpack('i', w_f.read(4))\n            if (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\n                w_f.read(8)\n            else:\n                w_f.read(4)\n            transpose = (major > 1000) or (minor > 1000)\n            binary = w_f.read()\n        self.offset = 0\n        self.all_weights = np.frombuffer(binary, dtype='float32')\n \n    def read_bytes(self, size):\n        self.offset = self.offset + size\n        return self.all_weights[self.offset-size:self.offset]\n\n    def load_weights(self, model):\n        for i in range(106):\n            try:\n                conv_layer = model.get_layer('conv_' + str(i))\n                print(\"loading weights of convolution #\" + str(i))\n                if i not in [81, 93, 105]:\n                    norm_layer = model.get_layer('bnorm_' + str(i))\n                    size = np.prod(norm_layer.get_weights()[0].shape)\n                    beta  = self.read_bytes(size) # bias\n                    gamma = self.read_bytes(size) # scale\n                    mean  = self.read_bytes(size) # mean\n                    var   = self.read_bytes(size) # variance\n                    weights = norm_layer.set_weights([gamma, beta, mean, var])\n                if len(conv_layer.get_weights()) > 1:\n                    bias   = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n                    kernel = kernel.transpose([2,3,1,0])\n                    conv_layer.set_weights([kernel, bias])\n                else:\n                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n                    kernel = kernel.transpose([2,3,1,0])\n                    conv_layer.set_weights([kernel])\n            except ValueError:\n                print(\"no convolution #\" + str(i))\n\n    def reset(self):\n        self.offset = 0","metadata":{"execution":{"iopub.status.busy":"2021-07-11T15:27:06.797911Z","iopub.execute_input":"2021-07-11T15:27:06.798208Z","iopub.status.idle":"2021-07-11T15:27:06.872597Z","shell.execute_reply.started":"2021-07-11T15:27:06.798181Z","shell.execute_reply":"2021-07-11T15:27:06.871663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot\nfrom matplotlib.patches import Rectangle\n \nclass BoundBox:\n    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n        self.xmin = xmin\n        self.ymin = ymin\n        self.xmax = xmax\n        self.ymax = ymax\n        self.objness = objness\n        self.classes = classes\n        self.label = -1\n        self.score = -1\n\n    def get_label(self):\n        if self.label == -1:\n            self.label = np.argmax(self.classes)\n\n        return self.label\n\n    def get_score(self):\n        if self.score == -1:\n            self.score = self.classes[self.get_label()]\n \n        return self.score\n \ndef _sigmoid(x):\n    return 1. / (1. + np.exp(-x))\n \ndef decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n    grid_h, grid_w = netout.shape[:2]\n    nb_box = 3\n    netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n    nb_class = netout.shape[-1] - 5\n    boxes = []\n    netout[..., :2]  = _sigmoid(netout[..., :2])\n    netout[..., 4:]  = _sigmoid(netout[..., 4:])\n    netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n    netout[..., 5:] *= netout[..., 5:] > obj_thresh\n \n    for i in range(grid_h*grid_w):\n        row = i / grid_w\n        col = i % grid_w\n        for b in range(nb_box):\n            objectness = netout[int(row)][int(col)][b][4]\n            if(objectness.all() <= obj_thresh): continue\n            x, y, w, h = netout[int(row)][int(col)][b][:4]\n            x = (col + x) / grid_w \n            y = (row + y) / grid_h \n            w = anchors[2 * b + 0] * np.exp(w) / net_w \n            h = anchors[2 * b + 1] * np.exp(h) / net_h \n            classes = netout[int(row)][col][b][5:]\n            box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n            boxes.append(box)\n    return boxes\n \ndef correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n    new_w, new_h = net_w, net_h\n    for i in range(len(boxes)):\n        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n\ndef _interval_overlap(interval_a, interval_b):\n    x1, x2 = interval_a\n    x3, x4 = interval_b\n    if x3 < x1:\n        if x4 < x1:\n            return 0\n        else:\n            return min(x2,x4) - x1\n    else:\n        if x2 < x3:\n            return 0\n        else:\n            return min(x2,x4) - x3\n\ndef bbox_iou(box1, box2):\n    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n    intersect = intersect_w * intersect_h\n    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n    union = w1*h1 + w2*h2 - intersect\n    return float(intersect) / union\n \ndef do_nms(boxes, nms_thresh):\n    if len(boxes) > 0:\n        nb_class = len(boxes[0].classes)\n    else:\n        return\n    for c in range(nb_class):\n        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n        for i in range(len(sorted_indices)):\n            index_i = sorted_indices[i]\n            if boxes[index_i].classes[c] == 0: continue\n            for j in range(i+1, len(sorted_indices)):\n                index_j = sorted_indices[j]\n                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n                    boxes[index_j].classes[c] = 0\ndef load_image_pixels(filename, shape):\n    image = load_img(filename)\n    width, height = image.size\n    image = load_img(filename, target_size=shape)\n    image = img_to_array(image)\n    image = image.astype('float32')\n    image /= 255.0\n    image = expand_dims(image, 0)\n    return image, width, height\n \ndef get_boxes(boxes, labels, thresh):\n    v_boxes, v_labels, v_scores = list(), list(), list()\n    for box in boxes:\n        for i in range(len(labels)):\n                if box.classes[i] > thresh:\n                    v_boxes.append(box)\n                    v_labels.append(labels[i])\n                    v_scores.append(box.classes[i]*100)\n    return v_boxes, v_labels, v_scores\n \ndef draw_boxes(filename, v_boxes, v_labels, v_scores):\n    data = pyplot.imread(filename)\n    pyplot.imshow(data)\n    ax = pyplot.gca()\n    for i in range(len(v_boxes)):\n        box = v_boxes[i]\n        y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n        width, height = x2 - x1, y2 - y1\n        rect = Rectangle((x1, y1), width, height, fill=False, color='white')\n        ax.add_patch(rect)\n        label = \"%s (%.3f)\" % (v_labels[i], v_scores[i])\n        pyplot.text(x1, y1, label, color='white')\n    pyplot.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T15:27:06.873835Z","iopub.execute_input":"2021-07-11T15:27:06.87421Z","iopub.status.idle":"2021-07-11T15:27:06.938434Z","shell.execute_reply.started":"2021-07-11T15:27:06.874181Z","shell.execute_reply":"2021-07-11T15:27:06.937502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = make_yolov3_model()\nweight_reader = WeightReader('../input/lyft-3d-recognition/yolov3.weights')\nweight_reader.load_weights(model)\nmodel.save('model.h5')","metadata":{"execution":{"iopub.status.busy":"2021-07-11T15:27:06.941081Z","iopub.execute_input":"2021-07-11T15:27:06.941578Z","iopub.status.idle":"2021-07-11T15:27:16.975652Z","shell.execute_reply.started":"2021-07-11T15:27:06.941547Z","shell.execute_reply":"2021-07-11T15:27:16.974723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\nmodel = load_model('model.h5')","metadata":{"execution":{"iopub.status.busy":"2021-07-11T15:27:16.977289Z","iopub.execute_input":"2021-07-11T15:27:16.977567Z","iopub.status.idle":"2021-07-11T15:27:19.962851Z","shell.execute_reply.started":"2021-07-11T15:27:16.97754Z","shell.execute_reply":"2021-07-11T15:27:19.961824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\nWIDTH, HEIGHT = 416, 416\nclass_threshold = 0.3","metadata":{"execution":{"iopub.status.busy":"2021-07-11T15:27:19.964109Z","iopub.execute_input":"2021-07-11T15:27:19.96439Z","iopub.status.idle":"2021-07-11T15:27:19.970111Z","shell.execute_reply.started":"2021-07-11T15:27:19.964364Z","shell.execute_reply":"2021-07-11T15:27:19.969169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom matplotlib import pyplot as plt\nimages = os.listdir('../input/3d-object-detection-for-autonomous-vehicles/train_images')[:100]\n#len(images) for whole dataset = 158757","metadata":{"execution":{"iopub.status.busy":"2021-07-11T15:27:19.971419Z","iopub.execute_input":"2021-07-11T15:27:19.971772Z","iopub.status.idle":"2021-07-11T15:27:32.183126Z","shell.execute_reply.started":"2021-07-11T15:27:19.971733Z","shell.execute_reply":"2021-07-11T15:27:32.182035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numpy import expand_dims\nfrom keras.preprocessing.image import load_img, img_to_array\ndef load_image_pixels(filename, shape):\n    image = load_img(filename)\n    width, height = image.size\n    image = load_img(filename, target_size=shape)\n    image = img_to_array(image)\n    image = image.astype('float32')\n    image /= 255.0\n    image = expand_dims(image, 0)\n    return image, width, height","metadata":{"execution":{"iopub.status.busy":"2021-07-11T15:27:32.184789Z","iopub.execute_input":"2021-07-11T15:27:32.18524Z","iopub.status.idle":"2021-07-11T15:27:32.194428Z","shell.execute_reply.started":"2021-07-11T15:27:32.185193Z","shell.execute_reply":"2021-07-11T15:27:32.19346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores_final = {\"person\":0, \"bicycle\":0, \"car\":0, \"motorbike\":0, \"aeroplane\":0, \"bus\":0, \"train\":0, \"truck\":0,\"boat\":0}\ncounter_final = {\"person\":0, \"bicycle\":0, \"car\":0, \"motorbike\":0, \"aeroplane\":0, \"bus\":0, \"train\":0, \"truck\":0,\"boat\":0}\n    \nfor file in images:\n    photo_filename = data + '/train_images/' + file\n    image, image_w, image_h = load_image_pixels(photo_filename, (WIDTH, HEIGHT))\n    yhat = model.predict(image)\n    boxes = list()\n    for i in range(len(yhat)):\n        boxes += decode_netout(yhat[i][0], anchors[i], .8, HEIGHT, WIDTH)\n    correct_yolo_boxes(boxes, image_h, image_w, HEIGHT, WIDTH)\n    do_nms(boxes, 0.5)\n    labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\",\"boat\"]\n    #v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n    v_boxes, v_labels, v_scores = get_boxes(boxes, labels, 0.8)\n    #for i in range(len(v_boxes)):\n    #    print(v_labels[i], v_scores[i])\n        \n    \n    for i in range(len(v_boxes)):\n        scores_final[v_labels[i]]+=v_scores[i]\n        counter_final[v_labels[i]]+=1\n    \n    \n        \nprint(scores_final)\nprint(counter_final)   \n    #draw_boxes(photo_filename, v_boxes, v_labels, v_scores)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T15:27:32.196033Z","iopub.execute_input":"2021-07-11T15:27:32.196345Z","iopub.status.idle":"2021-07-11T15:37:49.203562Z","shell.execute_reply.started":"2021-07-11T15:27:32.196317Z","shell.execute_reply":"2021-07-11T15:37:49.202243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#conf score calc\n\nfor i in labels:\n    if(counter_final[i]!=0):\n        print(\"conf score of\"+str(i)+\":\"+str(scores_final[i]/counter_final[i]))\n    else:\n        print(\"Conf score can't be displayed due to lack of samples of \"+str(i))","metadata":{"execution":{"iopub.status.busy":"2021-07-11T15:37:49.205757Z","iopub.execute_input":"2021-07-11T15:37:49.20614Z","iopub.status.idle":"2021-07-11T15:37:49.215281Z","shell.execute_reply.started":"2021-07-11T15:37:49.206095Z","shell.execute_reply":"2021-07-11T15:37:49.214227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = os.listdir('../input/3d-object-detection-for-autonomous-vehicles/train_images')[:10]\nfor file in images:\n    photo_filename = data + '/train_images/' + file\n    image, image_w, image_h = load_image_pixels(photo_filename, (WIDTH, HEIGHT))\n    yhat = model.predict(image)\n    boxes = list()\n    for i in range(len(yhat)):\n        boxes += decode_netout(yhat[i][0], anchors[i], .8, HEIGHT, WIDTH)\n    correct_yolo_boxes(boxes, image_h, image_w, HEIGHT, WIDTH)\n    do_nms(boxes, 0.5)\n    labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\",\"boat\"]\n    #v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n    v_boxes, v_labels, v_scores = get_boxes(boxes, labels, 0.8)\n    for i in range(len(v_boxes)):\n        print(v_labels[i], v_scores[i])\n        \n    \n    \n    \n    \n        \n\n    draw_boxes(photo_filename, v_boxes, v_labels, v_scores)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T15:37:49.216793Z","iopub.execute_input":"2021-07-11T15:37:49.21719Z","iopub.status.idle":"2021-07-11T15:38:55.684649Z","shell.execute_reply.started":"2021-07-11T15:37:49.217155Z","shell.execute_reply":"2021-07-11T15:38:55.683801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = os.listdir('../input/3d-object-detection-for-autonomous-vehicles/train_images')[:100]\n\nscores_final = {\"person\":0, \"bicycle\":0, \"car\":0, \"motorbike\":0, \"aeroplane\":0, \"bus\":0, \"train\":0, \"truck\":0,\"boat\":0}\ncounter_final = {\"person\":0, \"bicycle\":0, \"car\":0, \"motorbike\":0, \"aeroplane\":0, \"bus\":0, \"train\":0, \"truck\":0,\"boat\":0}\n    \nfor file in images:\n    photo_filename = data + '/train_images/' + file\n    image, image_w, image_h = load_image_pixels(photo_filename, (WIDTH, HEIGHT))\n    yhat = model.predict(image)\n    boxes = list()\n    for i in range(len(yhat)):\n        boxes += decode_netout(yhat[i][0], anchors[i], .75, HEIGHT, WIDTH)\n    correct_yolo_boxes(boxes, image_h, image_w, HEIGHT, WIDTH)\n    do_nms(boxes, 0.5)\n    labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\",\"boat\"]\n    #v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n    v_boxes, v_labels, v_scores = get_boxes(boxes, labels, 0.75)\n    #for i in range(len(v_boxes)):\n    #    print(v_labels[i], v_scores[i])\n        \n    \n    for i in range(len(v_boxes)):\n        scores_final[v_labels[i]]+=v_scores[i]\n        counter_final[v_labels[i]]+=1\n    \n    \n        \nprint(scores_final)\nprint(counter_final)   \n    #draw_boxes(photo_filename, v_boxes, v_labels, v_scores)\n \n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-11T15:38:55.685737Z","iopub.execute_input":"2021-07-11T15:38:55.686132Z","iopub.status.idle":"2021-07-11T15:49:20.879646Z","shell.execute_reply.started":"2021-07-11T15:38:55.686103Z","shell.execute_reply":"2021-07-11T15:49:20.878433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#conf score calc\n\nfor i in labels:\n    if(counter_final[i]!=0):\n        print(\"conf score of\"+str(i)+\":\"+str(scores_final[i]/counter_final[i]))\n    else:\n        print(\"Conf score can't be displayed due to lack of samples of \"+str(i))","metadata":{"execution":{"iopub.status.busy":"2021-07-11T15:49:20.881039Z","iopub.execute_input":"2021-07-11T15:49:20.88133Z","iopub.status.idle":"2021-07-11T15:49:20.888279Z","shell.execute_reply.started":"2021-07-11T15:49:20.881304Z","shell.execute_reply":"2021-07-11T15:49:20.887575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = os.listdir('../input/3d-object-detection-for-autonomous-vehicles/train_images')[:1]\nfor file in images:\n    photo_filename = data + '/train_images/' + file\n    image, image_w, image_h = load_image_pixels(photo_filename, (WIDTH, HEIGHT))\n    yhat = model.predict(image)\n    boxes = list()\n    for i in range(len(yhat)):\n        boxes += decode_netout(yhat[i][0], anchors[i], .8, HEIGHT, WIDTH)\n    correct_yolo_boxes(boxes, image_h, image_w, HEIGHT, WIDTH)\n    do_nms(boxes, 0.3)\n    labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\",\"boat\"]\n    #v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n    v_boxes, v_labels, v_scores = get_boxes(boxes, labels, 0.8)\n    for i in range(len(v_boxes)):\n        print(v_labels[i], v_scores[i])\n        \n    \n    \n    \n    \n        \n\n    draw_boxes(photo_filename, v_boxes, v_labels, v_scores)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T15:49:20.889294Z","iopub.execute_input":"2021-07-11T15:49:20.88974Z","iopub.status.idle":"2021-07-11T15:49:27.596361Z","shell.execute_reply.started":"2021-07-11T15:49:20.889667Z","shell.execute_reply":"2021-07-11T15:49:27.595691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ntrain_df = pd.read_csv('../input/3d-object-detection-for-autonomous-vehicles/train.csv')\ntrain_df.head()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-11T15:49:27.597621Z","iopub.execute_input":"2021-07-11T15:49:27.598122Z","iopub.status.idle":"2021-07-11T15:49:29.459098Z","shell.execute_reply.started":"2021-07-11T15:49:27.59809Z","shell.execute_reply":"2021-07-11T15:49:29.457952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ntrain_df = pd.read_csv('../input/3d-object-detection-for-autonomous-vehicles/train.csv')\ntrain_df['PredictionString'][0]\n","metadata":{"execution":{"iopub.status.busy":"2021-07-11T15:49:29.460758Z","iopub.execute_input":"2021-07-11T15:49:29.461186Z","iopub.status.idle":"2021-07-11T15:49:30.157131Z","shell.execute_reply.started":"2021-07-11T15:49:29.461144Z","shell.execute_reply":"2021-07-11T15:49:30.155977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\n  \n# Opening JSON file\nf = open('../input/3d-object-detection-for-autonomous-vehicles/train_data/sample_data.json',)\n  \n# returns JSON object as \n# a dictionary\ndata = json.load(f)\n  \n# Iterating through the json\n# list\nprint(\"printing data for one image\")\nprint(data[:1][:])\n\n\n  \n# Closing file\nf.close()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T15:49:30.158869Z","iopub.execute_input":"2021-07-11T15:49:30.159183Z","iopub.status.idle":"2021-07-11T15:49:34.410066Z","shell.execute_reply.started":"2021-07-11T15:49:30.159154Z","shell.execute_reply":"2021-07-11T15:49:34.408895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nWe use referencing on the following:\n\njson_file_entry[sample_token] = train_df[id]\njson_file_entry[filename] = images[file_name]\n\n\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-07-11T15:49:34.41178Z","iopub.execute_input":"2021-07-11T15:49:34.412205Z","iopub.status.idle":"2021-07-11T15:49:34.41786Z","shell.execute_reply.started":"2021-07-11T15:49:34.412161Z","shell.execute_reply":"2021-07-11T15:49:34.416671Z"},"trusted":true},"execution_count":null,"outputs":[]}]}